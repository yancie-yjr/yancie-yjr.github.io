<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Jinrong Yang</title> <meta name="author" content="Jinrong Yang"> <meta name="description" content="Homepage of Jinrong Yang. "> <meta name="keywords" content="Jinrong Yang"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://yancie-yjr.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Jinrong</span> Yang </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Hello! I am Jinrong Yang (杨金荣). I am a Senior Researcher at CVTE Research Institute &amp; Sun Yat-sen University, Guangzhou, China. In September 2024, I received my PhD degree from <a href="https://www.hust.edu.cn" rel="external nofollow noopener" target="_blank">Huazhong University of Science and Technology (HUST)</a>, supervised by <a href="http://mse.hust.edu.cn/info/1143/1374.htm" rel="external nofollow noopener" target="_blank">Xiaoping Li</a>, <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Xiangyu Zhang</a> and <a href="https://scholar.google.com/citations?user=hJ-VrrIAAAAJ" rel="external nofollow noopener" target="_blank">Zheng Ge</a>.</p> <p>My research interest mainly focus on <strong>Robotics, Computer Vision, and Multimodal learning</strong>.</p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Oct 14, 2024</th> <td> One paper(<strong>GEM</strong>) is accepted by IEEE TMM. </td> </tr> <tr> <th scope="row">Aug 19, 2024</th> <td> One paper(<strong>GroupLane</strong>) is accepted by IEEE RA-L. </td> </tr> <tr> <th scope="row">Jul 1, 2024</th> <td> Two papers (<strong>Vary, Merlin</strong>) about Multimodal LLM are accepted by ECCV’24. </td> </tr> <tr> <th scope="row">Jun 30, 2024</th> <td> Two papers (<strong>QTrack, VideoBEV</strong>) about the Perception of Autonomous Driving are accepted by IROS’24, and one is accepted as <strong>Oral Presentation</strong> paper. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Apr 16, 2024</th> <td> One paper (<strong>ChatSpot</strong>) about Multimodal LLM are accepted by IJCAI’24 as <strong>Long Oral</strong> paper. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jan 15, 2024</th> <td> One paper (<strong>DreamLLM</strong>) about Synergistic Multimodal Comprehension and Creation LLM is accepted by ICLR’24 as <strong>Spotlight</strong> paper. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jan 25, 2023</th> <td> My second paper of the corresponding author (<strong>PCET</strong>) is accepted by IEEE RA-L. Congratulations to Pan Wang! </td> </tr> <tr> <th scope="row">Jan 21, 2023</th> <td> One paper (<strong>DBQ-SSD</strong>) is accepted by ICLR 2023 </td> </tr> <tr> <th scope="row">Nov 1, 2022</th> <td> Three papers (<strong>BEVDepth, BEVStereo, LTrack</strong>) are accepted by AAAI’23. </td> </tr> <tr> <th scope="row">Mar 2, 2022</th> <td> One paper (<strong>StreamYOLO</strong>) is accepted by CVPR’22 as <strong>oral</strong> paper. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Sep 28, 2021</th> <td> One paper (<strong>COSOC</strong>) is accepted by NeurIPS’21. </td> </tr> </table> </div> </div> <div class="publications"> <h2>Selected publications</h2> <b>* indicates equal contribution,</b> <b>** indicates corresponding author.</b><br> <b> </b><br> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV’24</abbr></div> <div id="wei2025vary" class="col-sm-8"> <div class="title">Vary: Scaling up the Vision Vocabulary for Large Vision-Language Model</div> <div class="author"> En Yu, Liang Zhao, Yana Wei, Jinrong Yang, Dongming Wu, Lingyu Kong, Haoran Wei, Tiancai Wang, Zheng Ge, Xiangyu Zhang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceeding of the European Conference on Computer Vision (ECCV)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00613.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ECCV’24</abbr></div> <div id="ye2025merlin" class="col-sm-8"> <div class="title">Vary: Scaling up the Vision Vocabulary for Large Vision-Language Model</div> <div class="author"> Haoran Wei, Lingyu Kong, Jinyue Chen, Liang Zhao, Zheng Ge, Jinrong Yang, Jianjian Sun, Chunrui Han, and Xiangyu Zhang</div> <div class="periodical"> <em>In Proceeding of the European Conference on Computer Vision (ECCV)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://link.springer.com/chapter/10.1007/978-3-031-73235-5_23" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/dreamllm.png"></div> <div id="2024dreamllm" class="col-sm-8"> <div class="title">DreamLLM: Synergistic Multimodal Comprehension and Creation</div> <div class="author"> Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2309.11499.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2024dreamllm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DreamLLM: Synergistic Multimodal Comprehension and Creation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/chatspot.png"></div> <div id="zhao2023chatspot" class="col-sm-8"> <div class="title">ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning</div> <div class="author"> Liang Zhao, En Yu, Zheng Ge, Jinrong Yang, Haoran Wei, Hongyu Zhou, Jianjian Sun, Yuang Peng, Runpei Dong, Chunrui Han, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceeding of International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2307.09474.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhao2023chatspot</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhao, Liang and Yu, En and Ge, Zheng and Yang, Jinrong and Wei, Haoran and Zhou, Hongyu and Sun, Jianjian and Peng, Yuang and Dong, Runpei and Han, Chunrui and others}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of International Joint Conferences on Artificial Intelligence (IJCAI)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/videobev.png"></div> <div id="han2023exploring" class="col-sm-8"> <div class="title">Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D Perception</div> <div class="author"> Chunrui Han*, Jinrong Yang*, Jianjian Sun, Zheng Ge, Runpei Dong, Hongyu Zhou, Weixin Mao, Yuang Peng, and Xiangyu Zhang</div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10530939/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">han2023exploring</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring Recurrent Long-term Temporal Fusion for Multi-view 3D Perception}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han*, Chunrui and Yang*, Jinrong and Sun, Jianjian and Ge, Zheng and Dong, Runpei and Zhou, Hongyu and Mao, Weixin and Peng, Yuang and Zhang, Xiangyu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/qtrack.jpg"></div> <div id="yang2022quality" class="col-sm-8"> <div class="title">Quality Matters: Embracing Quality Clues for Robust 3D Multi-Object Tracking</div> <div class="author"> Jinrong Yang*, En Yu*, Zeming Li, Xiaoping Li, and Wenbing Tao</div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2208.10976.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yang2022quality</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Quality Matters: Embracing Quality Clues for Robust 3D Multi-Object Tracking}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang*, Jinrong and Yu*, En and Li, Zeming and Li, Xiaoping and Tao, Wenbing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/grouplane.png"></div> <div id="li2024grouplane" class="col-sm-8"> <div class="title">GroupLane: End-to-End 3D Lane Detection with Channel-wise Grouping</div> <div class="author"> Zhuoling Li, Chunrui Han, Zheng Ge, Jinrong Yang, En Yu, Haoqian Wang, Hengshuang Zhao, and Xiangyu Zhang</div> <div class="periodical"> <em>arXiv preprint arXiv:2307.09472</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10706836" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2024grouplane</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GroupLane: End-to-End 3D Lane Detection with Channel-wise Grouping}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhuoling and Han, Chunrui and Ge, Zheng and Yang, Jinrong and Yu, En and Wang, Haoqian and Zhao, Hengshuang and Zhang, Xiangyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2307.09472}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/gmm.png"></div> <div id="mao2023gmm" class="col-sm-8"> <div class="title">GMM: Delving into Gradient Aware and Model Perceive Depth Mining for Monocular 3D Detection</div> <div class="author"> Weixin Mao*, Jinrong Yang*, Zheng Ge, Lin Song, Hongyu Zhou, Tiezheng Mao, Zeming Li, and Osamu Yoshie</div> <div class="periodical"> <em>arXiv preprint arXiv:2306.17450</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2306.17450.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mao2023gmm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GMM: Delving into Gradient Aware and Model Perceive Depth Mining for Monocular 3D Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mao*, Weixin and Yang*, Jinrong and Ge, Zheng and Song, Lin and Zhou, Hongyu and Mao, Tiezheng and Li, Zeming and Yoshie, Osamu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2306.17450}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/dbqssd.jpg"></div> <div id="yang2022dbq" class="col-sm-8"> <div class="title">DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection</div> <div class="author"> Jinrong Yang*, Lin Song*, Songtao Liu, Weixin Mao, Zeming Li, Xiaoping Li, Hongbin Sun, Jian Sun, and Nanning Zheng</div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2207.10909.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yang2022dbq</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang*, Jinrong and Song*, Lin and Liu, Songtao and Mao, Weixin and Li, Zeming and Li, Xiaoping and Sun, Hongbin and Sun, Jian and Zheng, Nanning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/pcet.png"></div> <div id="wang2022implicit" class="col-sm-8"> <div class="title">Implicit and Efficient Point Cloud Completion for 3D Single Object Tracking</div> <div class="author"> Pan Wang, Liangliang Ren, Shengkai Wu, Jinrong Yang**, En Yu, Hangcheng Yu, and Xiaoping Li</div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2209.00522.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2022implicit</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Implicit and Efficient Point Cloud Completion for 3D Single Object Tracking}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Pan and Ren, Liangliang and Wu, Shengkai and Yang**, Jinrong and Yu, En and Yu, Hangcheng and Li, Xiaoping}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/bevdepth.jpg"></div> <div id="li2022bevdepth" class="col-sm-8"> <div class="title">BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection</div> <div class="author"> Yinhao Li, Zheng Ge, Guanyi Yu, Jinrong Yang, Zengran Wang, Yukang Shi, Jianjian Sun, and Zeming Li</div> <div class="periodical"> <em>In Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2206.10092" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Megvii-BaseDetection/BEVDepth" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2022bevdepth</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Yinhao and Ge, Zheng and Yu, Guanyi and Yang, Jinrong and Wang, Zengran and Shi, Yukang and Sun, Jianjian and Li, Zeming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/bevstereo.jpg"></div> <div id="li2022bevstereo" class="col-sm-8"> <div class="title">BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo</div> <div class="author"> Yinhao Li, Han Bao, Zheng Ge, Jinrong Yang, Jianjian Sun, and Zeming Li</div> <div class="periodical"> <em>In Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2209.10248" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Megvii-BaseDetection/BEVDepth" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2022bevstereo</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Yinhao and Bao, Han and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Li, Zeming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ltrake.jpg"></div> <div id="yu2022generalizing" class="col-sm-8"> <div class="title">Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation</div> <div class="author"> En Yu, Songtao Liu, Zhuoling Li, Jinrong Yang, Shoudong Han, Wenbing Tao, and  others</div> <div class="periodical"> <em>In Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2212.01568.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2022generalizing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, En and Liu, Songtao and Li, Zhuoling and Yang, Jinrong and Han, Shoudong and Tao, Wenbing and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of Association for the Advancement of Artificial Intelligence (AAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/streamyolo.jpg"></div> <div id="yang2022real" class="col-sm-8"> <div class="title">Real-time Object Detection for Streaming Perception</div> <div class="author"> Jinrong Yang, Songtao Liu, Zeming Li, Xiaoping Li, and Jian Sun</div> <div class="periodical"> <em>In Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yancie-yjr/StreamYOLO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yang2022real</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-time Object Detection for Streaming Perception}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Jinrong and Liu, Songtao and Li, Zeming and Li, Xiaoping and Sun, Jian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/free3d.png"></div> <div id="yang2022towards" class="col-sm-8"> <div class="title">Towards 3D Object Detection with 2D Supervision</div> <div class="author"> Jinrong Yang, Tiancai Wang, Zheng Ge, Weixin Mao, Xiaoping Li, and Xiangyu Zhang</div> <div class="periodical"> <em>arXiv preprint arXiv:2211.08287</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2211.08287.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yang2022towards</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards 3D Object Detection with 2D Supervision}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Jinrong and Wang, Tiancai and Ge, Zheng and Mao, Weixin and Li, Xiaoping and Zhang, Xiangyu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2211.08287}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/iou_balance.jpg"></div> <div id="wu2022iou" class="col-sm-8"> <div class="title">Iou-balanced Loss Functions for Single-stage Object Detection</div> <div class="author"> Shengkai Wu*, Jinrong Yang*, Xinggang Wang, and Xiaoping Li</div> <div class="periodical"> <em>Pattern Recognition Letters (PRL)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2208.10976.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2022iou</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Iou-balanced Loss Functions for Single-stage Object Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu*, Shengkai and Yang*, Jinrong and Wang, Xinggang and Li, Xiaoping}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pattern Recognition Letters (PRL)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/nisp2021.png"></div> <div id="luo2021rectifying" class="col-sm-8"> <div class="title">Rectifying the Shortcut Learning of Background for Few-shot Learning</div> <div class="author"> Xu Luo, Longhui Wei, Liangjian Wen, Jinrong Yang, Lingxi Xie, Zenglin Xu, and Qi Tian</div> <div class="periodical"> <em>In Proceeding of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper/2021/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Frankluox/LightningFSL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">luo2021rectifying</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rectifying the Shortcut Learning of Background for Few-shot Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Luo, Xu and Wei, Longhui and Wen, Liangjian and Yang, Jinrong and Xie, Lingxi and Xu, Zenglin and Tian, Qi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding of Advances in Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div> <h3>Collaborators</h3> <ul> <p> <a target="_blank" href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener">张祥雨(Xiangyu Zhang)</a>, <a target="_blank" href="https://www.zemingli.com/" rel="external nofollow noopener">黎泽明(Zeming Li)</a>, <a target="_blank" href="https://scholar.google.com/citations?user=hJ-VrrIAAAAJ" rel="external nofollow noopener">葛政(Zheng Ge)</a>, <a target="_blank" href="https://scholar.google.com/citations?hl=zh-CN&amp;user=xY9qK1QAAAAJ" rel="external nofollow noopener">刘松涛(Songtao Liu)</a> </p> </ul> </div> <div> <h4>Reviewer</h4> <ul> <p> <a><b>Computer Vision Conference: </b></a> <a>CVPR</a>, <a>ICCV</a>, <a>ECCV</a><br> <a><b>Machine Learning Conference: </b></a> <a>NeurIPS</a>, <a>ICLR</a>, <a>AAAI</a><br> <a><b>Robotics Conference: </b></a> <a>ICRA</a>, <a>IROS</a><br> <a><b>Journal: </b></a> <a>TPAMI</a>, <a>TCSVT</a>, <a>TMM</a>, <a>RA-L</a>, <a>PRL</a>, <a>IET CV</a> </p> </ul> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%79%61%6E%67%6A%69%6E%72%6F%6E%67@%68%75%73%74.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=8Of_NYQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/yancie-yjr" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Jinrong Yang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>